{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ff2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 检测图像的SIFT关键特征点\n",
    "def siftjiance(image):\n",
    "    # 将图像转换为灰度图\n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    # 获取图像特征sift-SIFT特征点,实例化对象sift  \n",
    "    sift = cv.SIFT_create()\n",
    "\n",
    "    keypoints, features = sift.detectAndCompute(image, None)\n",
    "\n",
    "    keypoints_image = cv.drawKeypoints(\n",
    "        gray_image, keypoints, None, flags=cv.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    return keypoints_image, keypoints, features\n",
    "\n",
    "\n",
    "# 使用KNN检测来自左右图像的SIFT特征，随后进行匹配\n",
    "def pointmatch(features_right, features_left):\n",
    "    # 创建BFMatcher对象解决匹配  \n",
    "    bf = cv.BFMatcher()\n",
    "\n",
    "    matches = bf.knnMatch(features_right, features_left, k=2)\n",
    "    # 利用sorted()函数对matches对象进行升序(默认)操作  \n",
    "    matches = sorted(matches, key=lambda x: x[0].distance / x[1].distance)\n",
    "\n",
    "    # 建立列表dots用于存储匹配的点集\n",
    "    dots = []\n",
    "    for m, n in matches:\n",
    "        # ratio的值越大，匹配的线条越密集，但错误匹配点也会增多\n",
    "        ratio = 0.6\n",
    "        if m.distance < ratio * n.distance:\n",
    "            dots.append(m)\n",
    "            # 返回匹配的关键特征点集\n",
    "    return dots\n",
    "\n",
    "\n",
    "# 计算视角变换矩阵H，用H对右图进行变换并返回全景拼接图像\n",
    "def pinjie(image_right, image_left):\n",
    "    _, keypoints_right, features_right = siftjiance(image_right)\n",
    "    _, keypoints_left, features_left = siftjiance(image_left)\n",
    "    goodMatch = pointmatch(features_right, features_left)\n",
    "    # 当筛选项的匹配对大于4对(因为homography单应性矩阵的计算需要至少四个点)时,计算视角变换矩阵  \n",
    "    if len(goodMatch) > 4:\n",
    "        # 获取匹配对的点坐标  \n",
    "        ptsR = np.float32(\n",
    "            [keypoints_right[m.queryIdx].pt for m in goodMatch]).reshape(-1, 1, 2)\n",
    "        ptsL = np.float32(\n",
    "            [keypoints_left[m.trainIdx].pt for m in goodMatch]).reshape(-1, 1, 2)\n",
    "        # ransacReprojThreshold：将点对视为内点的最大允许重投影错误阈值(仅用于RANSAC和RHO方法时),若srcPoints和dstPoints是以像素为单位的，该参数通常设置在1到10的范围内  \n",
    "        ransacReprojThreshold = 4\n",
    "        # cv.findHomography():计算多个二维点对之间的最优单映射变换矩阵 H(3行x3列),使用最小均方误差或者RANSAC方法  \n",
    "        # 函数作用:利用基于RANSAC的鲁棒算法选择最优的四组配对点，再计算转换矩阵H(3*3)并返回,以便于反向投影错误率达到最小  \n",
    "        Homography, status = cv.findHomography(\n",
    "            ptsR, ptsL, cv.RANSAC, ransacReprojThreshold)\n",
    "        # cv.warpPerspective()：透视变换函数，用于解决cv2.warpAffine()不能处理视场和图像不平行的问题  \n",
    "\n",
    "        jieguo = cv.warpPerspective(\n",
    "            image_right, Homography, (image_right.shape[1] + image_left.shape[1], image_right.shape[0]))\n",
    "\n",
    "        # 将左图加入到变换后的右图像的左端即获得最终图像  \n",
    "        jieguo[0:image_left.shape[0], 0:image_left.shape[1]] = image_left\n",
    "        # 返回全景拼接的图像 \n",
    "        return jieguo\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    image_left = cv.imread(\"5.png\")\n",
    "    image_right = cv.imread(\"6.png\")\n",
    "    # 通过调用cv2.resize()使用插值的方式来改变图像的尺寸，保证左右两张图像大小一致  \n",
    "\n",
    "    image_right = cv.resize(image_right, None, fx=1, fy=1)\n",
    "    image_left = cv.resize(image_left, (image_right.shape[1], image_right.shape[0]))\n",
    "    # 获取检测到关键特征点后的图像的相关参数  \n",
    "    keypoints_image_right, keypoints_right, features_right = siftjiance(image_right)\n",
    "    keypoints_image_left, keypoints_left, features_left = siftjiance(image_left)\n",
    "    # 利用np.hstack()函数同时将原图和绘有关键特征点的图像沿着竖直方向(水平顺序)堆叠起来  \n",
    "    cv.imshow(\"leftpoint\", np.hstack((image_left, keypoints_image_left)))\n",
    "\n",
    "    cv.waitKey(0)\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    cv.imshow(\"rightpoint\", np.hstack((image_right, keypoints_image_right)))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    goodMatch = pointmatch(features_right, features_left)\n",
    "\n",
    "\n",
    "    match_image = cv.drawMatches(\n",
    "        image_right, keypoints_right, image_left, keypoints_left, goodMatch, None, None, None, None, flags=2)\n",
    "    cv.imshow(\"match\", match_image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "    # 把图片拼接成全景图\n",
    "    jieguo = pinjie(image_right, image_left)\n",
    "\n",
    "    cv.imshow(\"result\", jieguo)\n",
    "\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee379b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c2312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
